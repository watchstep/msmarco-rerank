{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/watchstep/rerank/blob/dev/exllamav2_beir_rerank_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUr9EnAUlPTO"
      },
      "source": [
        "- [Promptagator: Few-shot Dense Retrieval From 8 Examples](https://arxiv.org/abs/2209.11755)\n",
        "- [InPars: Data Augmentation for Information Retrieval using Large Language Models.](https://arxiv.org/abs/2202.05144)\n",
        "\n",
        "- https://github.com/eric88525/UDADF/tree/master\n",
        "- https://blog.vespa.ai/improving-zero-shot-ranking-with-vespa-part-two/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv1mAPE7i0hq",
        "outputId": "bf5abd90-c03b-4b89-f903-c87df4afb6de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6wptmWpi2PR",
        "outputId": "5bf276a8-74b0-4040-f5fe-6fbb1827e844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting exllamav2\n",
            "  Downloading exllamav2-0.0.9-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.4/91.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beir\n",
            "  Downloading beir-2.0.0.tar.gz (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from exllamav2) (1.5.3)\n",
            "Collecting ninja (from exllamav2)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastparquet (from exllamav2)\n",
            "  Downloading fastparquet-2023.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from exllamav2) (2.1.0+cu118)\n",
            "Requirement already satisfied: safetensors>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from exllamav2) (0.4.0)\n",
            "Collecting sentencepiece>=0.1.97 (from exllamav2)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from exllamav2) (2.16.1)\n",
            "Collecting websockets (from exllamav2)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from exllamav2) (2023.6.3)\n",
            "Collecting sentence-transformers (from beir)\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytrec_eval (from beir)\n",
            "  Downloading pytrec_eval-0.5.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting faiss_cpu (from beir)\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting elasticsearch==7.9.1 (from beir)\n",
            "  Downloading elasticsearch-7.9.1-py2.py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.2/219.2 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from beir)\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from elasticsearch==7.9.1->beir) (2.0.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elasticsearch==7.9.1->beir) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->exllamav2) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->exllamav2) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->exllamav2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->exllamav2) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->exllamav2) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->exllamav2) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->exllamav2) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets->beir)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->beir)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (3.4.1)\n",
            "Collecting multiprocess (from datasets->beir)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->beir) (6.0.1)\n",
            "Collecting cramjam>=2.3 (from fastparquet->exllamav2)\n",
            "  Downloading cramjam-2.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->exllamav2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->exllamav2) (2023.3.post1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (4.35.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (0.16.0+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (1.11.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->beir) (3.8.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->beir) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->exllamav2) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->beir) (3.4)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers->beir) (0.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.1->exllamav2) (2.1.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers->beir) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers->beir) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->beir) (3.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.1->exllamav2) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers->beir) (9.4.0)\n",
            "Building wheels for collected packages: beir, pytrec_eval, sentence-transformers\n",
            "  Building wheel for beir (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for beir: filename=beir-2.0.0-py3-none-any.whl size=63550 sha256=1102f5735f1cd038118f07ded04907b664168f346ec5fbd454bb11674cc75411\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/14/96/c606ede3c10e9300ef771a6183af09d389459195ff5f854862\n",
            "  Building wheel for pytrec_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytrec_eval: filename=pytrec_eval-0.5-cp310-cp310-linux_x86_64.whl size=308205 sha256=16b65e3b4ebe7aee3457d2466daf61b412bf7d4ac62481bb5986a639492f68a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/3a/cd/dcc1ddfc763987d5cb237165d8ac249aa98a23ab90f67317a8\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=3323f3ebe1b59ab725894652ed3723e41fe4facfb15a1190522874adc6d7f2fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built beir pytrec_eval sentence-transformers\n",
            "Installing collected packages: sentencepiece, ninja, faiss_cpu, websockets, pytrec_eval, pyarrow-hotfix, elasticsearch, dill, cramjam, multiprocess, fastparquet, exllamav2, datasets, sentence-transformers, beir\n",
            "Successfully installed beir-2.0.0 cramjam-2.7.0 datasets-2.15.0 dill-0.3.7 elasticsearch-7.9.1 exllamav2-0.0.9 faiss_cpu-1.7.4 fastparquet-2023.10.1 multiprocess-0.70.15 ninja-1.11.1.1 pyarrow-hotfix-0.6 pytrec_eval-0.5 sentence-transformers-2.2.2 sentencepiece-0.1.99 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install exllamav2  beir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7SKofSti2al",
        "outputId": "28db0569-6c5c-4efa-a405-776d8ab14d0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n"
          ]
        }
      ],
      "source": [
        "!git lfs install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krBb0PZRi6Ri",
        "outputId": "41abded1-7057-4992-c168-b675d6b561e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mistral-7B-instruct-exl2'...\n",
            "remote: Enumerating objects: 52, done.\u001b[K\n",
            "remote: Total 52 (delta 0), reused 0 (delta 0), pack-reused 52\u001b[K\n",
            "Unpacking objects: 100% (52/52), 623.05 KiB | 2.01 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone -b 4.0bpw https://huggingface.co/turboderp/Mistral-7B-instruct-exl2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5wXIsU0nlWL"
      },
      "outputs": [],
      "source": [
        "import os, sys, argparse\n",
        "import json\n",
        "\n",
        "p_prompt = f\"\"\"\n",
        "Passage: <P> Given the provided passage, generate 3 similar passages on related topic: <T>\n",
        "\"\"\"\n",
        "\n",
        "q_prompt = \"\"\"\n",
        "<P> Review the given passages and answer a specific and detailed query. {'Query: Your query here.'}”\n",
        "\"\"\"\n",
        "\n",
        "parser = argparse.ArgumentParser(description = \"Prompting with ExLlamaV2\")\n",
        "parser.add_argument(\"--dataset\", type = str, default ='nq')\n",
        "parser.add_argument(\"--seed\", type = int, default = 2023)\n",
        "parser.add_argument(\"--topk\", type=int, default=10)\n",
        "parser.add_argument(\"--model_dir\", type=str, default=\"/content/Mistral-7B-instruct-exl2\")\n",
        "parser.add_argument(\"--p_prompt\", type=str, default=p_prompt)\n",
        "parser.add_argument(\"--q_prompt\", type=str, default=q_prompt)\n",
        "\n",
        "args = parser.parse_args([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "5ea33d9edd8e4f5fad41813e706460fa",
            "8ae8611f0b394c4c81810a8e86594125",
            "cd3783c7f26b4557adaeecb3162f3339",
            "0170d432d90b4a6da30303a8c77f62a3",
            "a5d716018628484fb568d2cf5845dfcc",
            "cc690372f9f64b3eb1cebac2d17a0c82",
            "e8b97eae61ed4d6f808769f1a3f333f3",
            "698b8fed871f49d48251094b02987496",
            "28f16ad502424374b422066628dba140",
            "1df6e2ed5faa4a0586b871ba95417e48",
            "1d7488fd32764583a1e3cde05b9b2aca",
            "6d54a072641c4f7db62b5705a0429f0f",
            "cdb4eceef9ae4cf48cf67772d328d185",
            "ba0a059eb61341779e788decca2724aa",
            "1889ef803bc44fe9ac083dba1f45fdd8",
            "d9a87d971db84ed9ad755fe7b89c48c0",
            "c62fd8f80037419490dbf756f0fdc352",
            "1e625ca792614daf93de6e91a00b3d03",
            "dad9a8fb559b4be59ae2d49ad3f15b8a",
            "5fea1865e1164f17b9a80a7db444e713",
            "1859ac4a330a4dc7b737a43884cb9595",
            "bf37b6a4a6674cdfbc8c00183fb26385"
          ]
        },
        "id": "SDUNVYV_jL5M",
        "outputId": "bfee8cf0-290d-4ad9-a81e-64516f3b602f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/beir/util.py:2: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/content/nq.zip:   0%|          | 0.00/475M [00:00<?, ?iB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ea33d9edd8e4f5fad41813e706460fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2681468 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d54a072641c4f7db62b5705a0429f0f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from beir import util\n",
        "from beir.datasets.data_loader import GenericDataLoader\n",
        "\n",
        "url = f\"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{args.dataset}.zip\"\n",
        "data_path = util.download_and_unzip(url, '/content')\n",
        "\n",
        "corpus, queries, qrels = GenericDataLoader(data_folder=data_path).load(split=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Atc4Z4GcCbFO",
        "outputId": "17b2aefc-761b-4887-ee98-cfc3f20e2e36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "elasticsearch-oss-7.9.2-linux-x86_64.tar.gz: OK\n"
          ]
        }
      ],
      "source": [
        "# download & setup Elasticsearch\n",
        "%%bash\n",
        "\n",
        "wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.9.2-linux-x86_64.tar.gz\n",
        "wget -q https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-oss-7.9.2-linux-x86_64.tar.gz.sha512\n",
        "tar -xzf elasticsearch-oss-7.9.2-linux-x86_64.tar.gz\n",
        "sudo chown -R daemon:daemon elasticsearch-7.9.2/\n",
        "shasum -a 512 -c elasticsearch-oss-7.9.2-linux-x86_64.tar.gz.sha512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eFMGMogCfVi"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "\n",
        "sudo -H -u daemon elasticsearch-7.9.2/bin/elasticsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5NuFZh8Ch1Q",
        "outputId": "d0fa0577-ce49-4147-cb56-050b624baf13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        2906    2901  0 06:31 ?        00:00:00 sudo -H -u daemon elasticsearch-7.9.2/bin/elasti\n",
            "daemon      2907    2906 39 06:31 ?        00:00:17 /content/elasticsearch-7.9.2/jdk/bin/java -Xshar\n",
            "root        3322    3320  0 06:32 ?        00:00:00 grep elasticsearch\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "ps -ef | grep elasticsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pekqc5FVCmCv",
        "outputId": "a027c072-585b-4e84-c382-0d71f57bb5a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"name\" : \"dfdcb6919169\",\n",
            "  \"cluster_name\" : \"elasticsearch\",\n",
            "  \"cluster_uuid\" : \"9fLaMVCpR9q87we_5jb0Zw\",\n",
            "  \"version\" : {\n",
            "    \"number\" : \"7.9.2\",\n",
            "    \"build_flavor\" : \"oss\",\n",
            "    \"build_type\" : \"tar\",\n",
            "    \"build_hash\" : \"d34da0ea4a966c4e49417f2da2f244e3e97b4e6e\",\n",
            "    \"build_date\" : \"2020-09-23T00:45:33.626720Z\",\n",
            "    \"build_snapshot\" : false,\n",
            "    \"lucene_version\" : \"8.6.2\",\n",
            "    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n",
            "    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n",
            "  },\n",
            "  \"tagline\" : \"You Know, for Search\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "curl -sX GET \"localhost:9200/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QvoBGp7BsIQ",
        "outputId": "c7f75222-3ae7-457f-f1eb-fda0294e2f68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2681468 [00:00<?, ?docs/s]\n",
            "que: 100%|██████████| 27/27 [09:50<00:00, 21.88s/it]\n"
          ]
        }
      ],
      "source": [
        "from beir.retrieval.search.lexical import BM25Search as BM25\n",
        "from beir.retrieval.evaluation import EvaluateRetrieval\n",
        "\n",
        "hostname = \"localhost\"\n",
        "index_name = \"nq\"\n",
        "initialize = True\n",
        "\n",
        "model = BM25(index_name=index_name, hostname=hostname, initialize=initialize)\n",
        "retriever = EvaluateRetrieval(model)\n",
        "\n",
        "results = retriever.retrieve(corpus, queries)\n",
        "# ndcg, _map, recall, precision = retriever.evaluate(qrels, results, retriever.k_values)\n",
        "output = {'retrieval': EvaluateRetrieval.evaluate(qrels, results, retriever.k_values)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mKv_DVi5wUl"
      },
      "outputs": [],
      "source": [
        "# save retrieved\n",
        "with open(f'/content/drive/MyDrive/{args.dataset}_bm25_es_retrieved.json', 'w') as f:\n",
        "  json.dump(results, f, indent=4)\n",
        "\n",
        "# save output tmp\n",
        "with open(f'/content/drive/MyDrive/{args.dataset}_eval_output.json', 'w') as f:\n",
        "  json.dump(output, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2B2o-st6W-f"
      },
      "outputs": [],
      "source": [
        "def save_json(results, file_name:str):\n",
        "  json_path = f'/content/drive/MyDrive/{args.dataset}_{file_name}.json'\n",
        "  with open(json_path, 'w') as f:\n",
        "    json.dump(results, f, indent=4)\n",
        "\n",
        "def read_json(json_path:str):\n",
        "  with open(json_path, 'r') as f:\n",
        "    data = f.read()\n",
        "  output = json.loads(data)\n",
        "\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97I2QQrmP6QM"
      },
      "outputs": [],
      "source": [
        "results = read_json(f'/content/drive/MyDrive/{args.dataset}_bm25_es_retrieved_.json')\n",
        "output = read_json(f'/content/drive/MyDrive/{args.dataset}_eval_ouput.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tqyTfyo-yVQ"
      },
      "outputs": [],
      "source": [
        "from exllamav2 import(\n",
        "    ExLlamaV2,\n",
        "    ExLlamaV2Config,\n",
        "    ExLlamaV2Cache,\n",
        "    ExLlamaV2Tokenizer,\n",
        ")\n",
        "\n",
        "from exllamav2.generator import (\n",
        "    ExLlamaV2BaseGenerator,\n",
        "    ExLlamaV2Sampler\n",
        ")\n",
        "\n",
        "# from beir.reranking import Rerank\n",
        "from typing import List, Tuple\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/beir-cellar/beir/blob/main/beir/reranking/rerank.py\n",
        "from typing import Dict, List\n",
        "\n",
        "class Rerank:\n",
        "  def __init__(self, model, batch_size: int = 128, **kwargs):\n",
        "    self.model = model\n",
        "    self.batch_size = batch_size\n",
        "    self.rerank_results = {}\n",
        "\n",
        "  def rerank(self,\n",
        "             corpus: Dict[str, Dict[str, str]],\n",
        "             queries: Dict[str, str],\n",
        "             results: Dict[str, Dict[str, float]],\n",
        "             top_k: int) -> Dict[str, Dict[str, float]]:\n",
        "\n",
        "    sentence_pairs, pair_ids = [], []\n",
        "\n",
        "    for query_id in results:\n",
        "      if len(results[query_id]) > top_k:\n",
        "        for (doc_id, _) in sorted(results[query_id].items(), key=lambda item: item[1], reverse=True)[:top_k]:\n",
        "          pair_ids.append([query_id, doc_id])\n",
        "          corpus_text = {'title': corpus[doc_id].get(\"title\", \"\").strip(), 'text': corpus[doc_id].get(\"text\", \"\").strip()}\n",
        "          sentence_pairs.append([queries[query_id], corpus_text])\n",
        "\n",
        "      else:\n",
        "        for doc_id in results[query_id]:\n",
        "          pair_ids.append([query_id, doc_id])\n",
        "          corpus_text = {'title': corpus[doc_id].get(\"title\", \"\").strip(), 'text': corpus[doc_id].get(\"text\", \"\").strip()}\n",
        "          # corpus_text = (corpus[doc_id].get(\"title\", \"\") + \" \" + corpus[doc_id].get(\"text\", \"\")).strip()\n",
        "          sentence_pairs.append([queries[query_id], corpus_text])\n",
        "\n",
        "    #### Starting to Rerank using cross-attention\n",
        "    rerank_scores = [float(score) for score in self.model.predict(sentence_pairs, batch_size=self.batch_size)]\n",
        "\n",
        "    #### Reranking results\n",
        "    self.rerank_results = {query_id: {} for query_id in results}\n",
        "    for pair, score in zip(pair_ids, rerank_scores):\n",
        "      query_id, doc_id = pair[0], pair[1]\n",
        "      self.rerank_results[query_id][doc_id] = score\n",
        "\n",
        "    return self.rerank_results"
      ],
      "metadata": {
        "id": "xJZhT-cGXU7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNgyL8V0Ylj9"
      },
      "outputs": [],
      "source": [
        "# https://github.com/beir-cellar/beir/wiki/Evaluate-your-custom-model\n",
        "# https://github.com/Muennighoff/sgpt/blob/main/crossencoder/beir/sgptce.py\n",
        "# https://github.com/beir-cellar/beir/blob/main/examples/retrieval/evaluation/reranking/evaluate_bm25_ce_reranking.py\n",
        "# https://github.com/beir-cellar/beir/blob/main/beir/reranking/models/mono_t5.py\n",
        "\n",
        "class ExLlamaV2Reranker:\n",
        "  def __init__(self, p_prompt=args.p_prompt, q_prompt=args.q_prompt, model_dir=args.model_dir, seed=args.seed, max_new_tokens=400, **kwargs):\n",
        "    self.p_prompt = p_prompt\n",
        "    self.q_prompt = q_prompt\n",
        "    self.seed = seed\n",
        "    self.max_new_tokens = max_new_tokens\n",
        "\n",
        "    self.config = ExLlamaV2Config()\n",
        "    self.config.model_dir = model_dir\n",
        "    self.config.prepare()\n",
        "\n",
        "    self.model = ExLlamaV2(self.config)\n",
        "    if not self.model.loaded:\n",
        "      self.cache = ExLlamaV2Cache(self.model, lazy = True)\n",
        "      self.model.load_autosplit(self.cache)\n",
        "\n",
        "    self.tokenizer = ExLlamaV2Tokenizer(self.config)\n",
        "    self.generator = ExLlamaV2BaseGenerator(self.model, self.cache, self.tokenizer)\n",
        "    self.generator.warmup()\n",
        "\n",
        "    self.settings = ExLlamaV2Sampler.Settings()\n",
        "    self.settings.temperature = 0.6\n",
        "    self.settings.top_k = 50\n",
        "    self.settings.top_p = 0.9\n",
        "    self.settings.token_repetition_penalty = 1.15\n",
        "    self.settings.disallow_tokens(self.tokenizer, [self.tokenizer.eos_token_id])\n",
        "\n",
        "  def predict(self, sentences: List[Tuple[str,str]], batch_size: int, **kwags) -> List[float]:\n",
        "    scores = []\n",
        "    for query, psg in sentences:\n",
        "      self.p_prompt = self.p_prompt.replace('<P>', psg['text']).replace('<T>', psg['title']).strip()\n",
        "      generated = self.generator.generate_simple(self.p_prompt, self.settings, self.max_new_tokens, seed=self.seed)\n",
        "      self.q_prompt = self.q_prompt.replace('<P>', generated).strip()\n",
        "      with torch.inference_mode():\n",
        "        input_ids = self.tokenizer.encode(self.q_prompt)\n",
        "        # input_ids = input_ids.shape[-1]\n",
        "        # self.cache.current_seq_len = 0\n",
        "        logits = self.model.forward(input_ids[:, -1:], self.cache)\n",
        "        logits = logits[:, :-1, :]\n",
        "        logits = logits.float() + 1e-10\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "\n",
        "      scores.append(log_probs)\n",
        "\n",
        "    assert len(scores) == len(sentences)\n",
        "    return scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhA2240iDDCZ"
      },
      "outputs": [],
      "source": [
        "reranker = Rerank(ExLlamaV2Reranker(), batch_size=128)\n",
        "rerank_results = reranker.rerank(corpus, queries, results, top_k=10)\n",
        "# rerank_results = reranker.rerank(corpus, queries, results, top_k=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TzvjK2jyJi4"
      },
      "outputs": [],
      "source": [
        "# save output\n",
        "output['reranking'] = EvaluateRetrieval.evaluate(qrels, rerank_results, retriever.k_values)\n",
        "\n",
        "with open(f'/content/{args.dataset}_eval_ouput.json', 'w') as f:\n",
        "  json.dump(output, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random, logging\n",
        "\n",
        "top_k = 10\n",
        "\n",
        "query_id, ranking_scores = random.choice(list(rerank_results.items()))\n",
        "scores_sorted = sorted(ranking_scores.items(), key=lambda item: item[1], reverse=True)\n",
        "logging.info(\"Query : %s\\n\" % queries[query_id])\n",
        "\n",
        "for rank in range(top_k):\n",
        "  doc_id = scores_sorted[rank][0]\n",
        "  # Format: Rank x: ID [Title] Body\n",
        "  logging.info(\"Rank %d: %s [%s] - %s\\n\" % (rank+1, doc_id, corpus[doc_id].get(\"title\"), corpus[doc_id].get(\"text\")))"
      ],
      "metadata": {
        "id": "bRKbBzHMiOSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXlCwF9C65g9"
      },
      "source": [
        "### Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4PoQhNJjOfL"
      },
      "outputs": [],
      "source": [
        "te_text = corpus['doc787']['text']\n",
        "te_title = corpus['doc787']['title']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9y_cfvmjQiY"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Passage: {te_text} Please generate 3 passages akin to the given passages, focusing on {te_title}\n",
        "\"\"\"\n",
        "\n",
        "# max_new_tokens = 400\n",
        "\n",
        "output = generator.generate_simple(prompt, settings, seed = 2023)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCKq-CDQjSGf"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "Passage: {te_text} Given the provided passage, generate 3 similar passages on related title {te_title}\n",
        "\"\"\"\n",
        "\n",
        "max_new_tokens = 400\n",
        "\n",
        "output = generator.generate_simple(prompt, settings, max_new_tokens, seed = 2023)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmA30M7RjUvx"
      },
      "outputs": [],
      "source": [
        "prompt2 = f\"{output} Review the given passages and answer a specific and detailed query. {'Query: Your query here.'}\"\n",
        "max_new_tokens = 30\n",
        "\n",
        "output2 = generator.generate_simple(prompt2, settings, max_new_tokens, seed = 2023)\n",
        "print(output2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIO9sD2GjWYM"
      },
      "outputs": [],
      "source": [
        "class NQDataset:\n",
        "  def __init__(self, corpus, queries):\n",
        "    self.corpus = corpus\n",
        "    self.queries = queries\n",
        "    self.qids = list(queries.keys())\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.qids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    query = self.queries[self.qids[idx]]\n",
        "    return query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUkhO-Hoo6Af"
      },
      "outputs": [],
      "source": [
        "with torch.inference_mode():\n",
        "  cache = ExLlamaV2Cache(model)\n",
        "\n",
        "  input_ids1 = tokenizer.encode(prompt1)\n",
        "  logits = model.forward(input_ids, cache)\n",
        "\n",
        "\n",
        "  output1 = generator.generate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n12YSeNjjXoI"
      },
      "outputs": [],
      "source": [
        "input_ids = tokenizer.encode(prompt1)\n",
        "prompt_tokens = input_ids.shape[-1]\n",
        "\n",
        "output = generator.generate(batch[\"input_ids\"].cuda(), settings, seed=2023)\n",
        "\n",
        "decode"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "xXlCwF9C65g9"
      ],
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPGRZkLNp4ur3edCJFVLX9G",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5ea33d9edd8e4f5fad41813e706460fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ae8611f0b394c4c81810a8e86594125",
              "IPY_MODEL_cd3783c7f26b4557adaeecb3162f3339",
              "IPY_MODEL_0170d432d90b4a6da30303a8c77f62a3"
            ],
            "layout": "IPY_MODEL_a5d716018628484fb568d2cf5845dfcc"
          }
        },
        "8ae8611f0b394c4c81810a8e86594125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc690372f9f64b3eb1cebac2d17a0c82",
            "placeholder": "​",
            "style": "IPY_MODEL_e8b97eae61ed4d6f808769f1a3f333f3",
            "value": "/content/nq.zip: 100%"
          }
        },
        "cd3783c7f26b4557adaeecb3162f3339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_698b8fed871f49d48251094b02987496",
            "max": 498307926,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28f16ad502424374b422066628dba140",
            "value": 498307926
          }
        },
        "0170d432d90b4a6da30303a8c77f62a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1df6e2ed5faa4a0586b871ba95417e48",
            "placeholder": "​",
            "style": "IPY_MODEL_1d7488fd32764583a1e3cde05b9b2aca",
            "value": " 475M/475M [00:09&lt;00:00, 78.1MiB/s]"
          }
        },
        "a5d716018628484fb568d2cf5845dfcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc690372f9f64b3eb1cebac2d17a0c82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8b97eae61ed4d6f808769f1a3f333f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "698b8fed871f49d48251094b02987496": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28f16ad502424374b422066628dba140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1df6e2ed5faa4a0586b871ba95417e48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d7488fd32764583a1e3cde05b9b2aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d54a072641c4f7db62b5705a0429f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdb4eceef9ae4cf48cf67772d328d185",
              "IPY_MODEL_ba0a059eb61341779e788decca2724aa",
              "IPY_MODEL_1889ef803bc44fe9ac083dba1f45fdd8"
            ],
            "layout": "IPY_MODEL_d9a87d971db84ed9ad755fe7b89c48c0"
          }
        },
        "cdb4eceef9ae4cf48cf67772d328d185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c62fd8f80037419490dbf756f0fdc352",
            "placeholder": "​",
            "style": "IPY_MODEL_1e625ca792614daf93de6e91a00b3d03",
            "value": "100%"
          }
        },
        "ba0a059eb61341779e788decca2724aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dad9a8fb559b4be59ae2d49ad3f15b8a",
            "max": 2681468,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5fea1865e1164f17b9a80a7db444e713",
            "value": 2681468
          }
        },
        "1889ef803bc44fe9ac083dba1f45fdd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1859ac4a330a4dc7b737a43884cb9595",
            "placeholder": "​",
            "style": "IPY_MODEL_bf37b6a4a6674cdfbc8c00183fb26385",
            "value": " 2681468/2681468 [00:23&lt;00:00, 98820.96it/s]"
          }
        },
        "d9a87d971db84ed9ad755fe7b89c48c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c62fd8f80037419490dbf756f0fdc352": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e625ca792614daf93de6e91a00b3d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dad9a8fb559b4be59ae2d49ad3f15b8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fea1865e1164f17b9a80a7db444e713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1859ac4a330a4dc7b737a43884cb9595": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf37b6a4a6674cdfbc8c00183fb26385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}