{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import requests\n",
    "import tarfile\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "import pyserini\n",
    "from pyserini.search import SimpleSearcher\n",
    "from pyserini.dsearch import SimpleDenseSearcher\n",
    "\n",
    "import transformers\n",
    "# from transformers import set_seed\n",
    "# set_seed(42)\n",
    "\n",
    "from peft import LoraConfig\n",
    "from transformers import (AutoTokenizer, \n",
    "                          AutoModelForCausalLM, \n",
    "                          BitsAndBytesConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Reranking with LLaMA2')\n",
    "\n",
    "parser.add_argument('--model_name', type=str, default='Llama-2-7b-hf')\n",
    "parser.add_argument('--dataset', type=str, default='msmarco-passage')\n",
    "parser.add_argument('--data_path', type=str, default='./collections/')\n",
    "parser.add_argument('--seed',type=int, default=42)\n",
    "parser.add_argument('--batch_size', type=int, default=256)\n",
    "parser.add_argument('--max_len', type=int, default=40)\n",
    "parser.add_argument('--lr', type=float, default=1e-5)\n",
    "parser.add_argument('--max_epochs', type=int, default=10)\n",
    "parser.add_argument('--use_cuda', type=bool, default=False)\n",
    "parser.add_argument('--k', type=int, default=100, help='top k')\n",
    "parser.add_argument('--k1', type=float, default=1.5, help='BM25 parameter')\n",
    "parser.add_argument('--b', type=float, default=0.75, help='BM25 parameter')\n",
    "\n",
    "parser.add_argument\n",
    "\n",
    "config = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(config.data_path, config.dataset)\n",
    "targz_path = os.path.join(dataset_path, 'collectionandqueries.tar.gz')\n",
    "msmarco_url = 'https://msmarco.blob.core.windows.net/msmarcoranking/collectionandqueries.tar.gz'\n",
    "tsv_path = os.path.join(dataset_path, 'collection.tsv')\n",
    "jsonl_path = os.path.join(dataset_path, 'collection_jsonl')\n",
    "index_path = os.path.join('./indexes', 'lucene-index-msmarco-passage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "# https://github.com/castorini/pyserini/blob/master/docs/experiments-msmarco-passage.md\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.mkdir(dataset_path)\n",
    "\n",
    "response = requests.get(msmarco_url, stream=True)\n",
    "file = tarfile.open(fileobj=response.raw, mode='r|gz')\n",
    "file.extractall(path=dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsv to jsonl\n",
    "os.system(f'python anserini-tools/scripts/msmarco/convert_collection_to_jsonl.py ' +\n",
    "          f'--collection-path {tsv_path} ' +\n",
    "          f'--output-folder {jsonl_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing for BM25\n",
    "# https://github.com/castorini/pyserini/blob/master/docs/usage-index.md#building-a-bm25-index-direct-java-implementation\n",
    "os.system('python -m pyserini.index.lucene ' + \n",
    "          '--collection JsonCollection ' +\n",
    "          f'--input {jsonl_path} ' +\n",
    "          f'--index {index_path} ' +\n",
    "          '--generator DefaultLuceneDocumentGenerator ' +\n",
    "          '--threads 1 --storeRaw')\n",
    "\n",
    "# --storePositions: builds a standard positional index\n",
    "# --storeDocvectors: stores doc vectors (required for relevance feedback)\n",
    "# --storeRaw: stores raw documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini.search.lucene import LuceneSearcher\n",
    "\n",
    "searcher = LuceneSearcher('indexes/lucene-index-msmarco-passage')\n",
    "\n",
    "hits = searcher.search('what is rba')\n",
    "\n",
    "for i in range(0, 5):\n",
    "    print(f'{i+1:2} {hits[i].docid:7} {hits[i].score:.6f}')\n",
    "    print(json.loads(hits[i].raw)['contents']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing for ANCE \n",
    "# os.system('python -m pyserini.encode ' + \n",
    "#           'input   --corpus tests/resources/simple_cacm_corpus.json ' +\n",
    "#                    '--fields text ' +\n",
    "#           'output  --embeddings {index_path} ' + \n",
    "#                     '--to-faiss ' + \n",
    "#           'encoder --encoder castorini/ance-msmarco-doc-maxp ' + #  --encoder castorini/tct_colbert-v2-hnp-msmarco TCT ColBERT\n",
    "#                    '--fields text ' + \n",
    "#                    '--batch 64 --device cpu ')\n",
    "\n",
    "# python -m pyserini.index.faiss \\\n",
    "#   --input path/to/encoded/corpus \\  # in jsonl format\n",
    "#   --output path/to/output/index \\\n",
    "    \n",
    "# from pyserini.search import FaissSearcher\n",
    "\n",
    "# searcher = FaissSearcher(\n",
    "#     'indexes/dindex-sample-dpr-multi',\n",
    "#     'facebook/dpr-question_encoder-multiset-base'\n",
    "# )\n",
    "# hits = searcher.search('what is a lobster roll')\n",
    "\n",
    "# for i in range(0, 10):\n",
    "#     print(f'{i+1:2} {hits[i].docid:7} {hits[i].score:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pyserini.search.lucene import LuceneSearcher \n",
    "\n",
    "# Indexer # Retriever # BaseRetriever 만들고 BM25, ANCE, Hybrid\n",
    "# build_sparse_index \n",
    "# build_dense_index\n",
    "# ssearch, dsearch, hsearch\n",
    "\n",
    "class BM25Retriever:\n",
    "    def __init__(self, jsonl_path, index_path, k1=1.5, b=0.75):\n",
    "        self.jsonl_path = jsonl_path\n",
    "        if not os.path.exists(index_path):\n",
    "            self.build_sparse_index(jsonl_path, index_path)\n",
    "        self.searcher = LuceneSearcher(index_path) # searcher = SimpleSearcher.from_prebuilt_index('msmarco-passage')\n",
    "        self.searcher.set_bm25(k1=k1, b=b)\n",
    "        # self.searcher.set_language()\n",
    "    \n",
    "    def build_sparse_index(self, jsonl_path, index_path): # 나중에 dense, hybird하기 위해 build_dense_index 만들고 새로운 class 만들기\n",
    "        execute_code = os.system('python -m pyserini.index.lucene ' + \n",
    "                                 '--collection JsonCollection ' +\n",
    "                                 f'--input {jsonl_path} ' +\n",
    "                                 f'--index {index_path} ' +\n",
    "                                 '--generator DefaultLuceneDocumentGenerator ' +\n",
    "                                 '--threads 1 --storeRaw')\n",
    "        if execute_code != 0:\n",
    "            raise Exception('Indexing Failed!')\n",
    "        else:\n",
    "            print('Indexing Success!')\n",
    "            \n",
    "    def _get_results(self, qid, hits:List):\n",
    "        results = []\n",
    "        \n",
    "        for i, hit in enumerate(hits):\n",
    "            docid = hit.docid\n",
    "            content = json.loads(hits[i].raw)['contents']\n",
    "            bm25_score = hit.score\n",
    "            result = {'rank': i,\n",
    "                      'qid': qid,\n",
    "                      'docid': docid, \n",
    "                      'bm25_score': bm25_score,\n",
    "                      'content': content}\n",
    "            results.append(result)\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    def search(self, qid, query:str, k:int=10):\n",
    "        hits = self.searcher.search(query, k=k)\n",
    "        search_results  = self._get_results(qid, hits)\n",
    "        \n",
    "        return search_results\n",
    "    \n",
    "    def batch_search(self, queries: List[str], qids: List[str], k:int=10):\n",
    "        batch_hits = self.searcher.batch_search(queries, qids, k=k)\n",
    "        bsearch_results = {}\n",
    "        \n",
    "        for qid, hits in batch_hits.items():\n",
    "            bsearch_results[qid] = self._get_results(qid, hits)\n",
    "        \n",
    "        return bsearch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_results = torch.topk(scores, k=5).indices \n",
    "# reranked_corpus = [corpus[i] for i in top_results] \n",
    "\n",
    "# scored_articles = zip(articles, cosine_similarities)\n",
    "\n",
    "# # Sort articles by cosine similarity\n",
    "# sorted_articles = sorted(scored_articles, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# scores = []\n",
    "# https://github.com/amazon-science/datatuner/blob/f70369659e1c58e6ddb44d6db467978679dbdd3c/src/datatuner/lm/reranker.py#L5 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rerank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
