{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import requests\n",
    "import tarfile\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "import pyserini\n",
    "from pyserini.search import SimpleSearcher\n",
    "from pyserini.dsearch import SimpleDenseSearcher\n",
    "\n",
    "import transformers\n",
    "# from transformers import set_seed\n",
    "# set_seed(42)\n",
    "\n",
    "from peft import LoraConfig\n",
    "from transformers import (AutoTokenizer, \n",
    "                          AutoModelForCausalLM, \n",
    "                          BitsAndBytesConfig)\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Reranking with LLaMA2')\n",
    "\n",
    "parser.add_argument('--model', type=str, default='meta-llama/Llama-2-7b-hf', help='model name')\n",
    "parser.add_argument('--dataset', type=str, default='msmarco-passage',)\n",
    "parser.add_argument('--data_path', type=str, default='./collection/')\n",
    "parser.add_argument('--seed',type=int, default=42)\n",
    "parser.add_argument('--batch_size', type=int, default=256)\n",
    "parser.add_argument('--max_len', type=int, default=40)\n",
    "parser.add_argument('--lr', type=float, default=1e-5)\n",
    "parser.add_argument('--max_epochs', type=int, default=10)\n",
    "parser.add_argument('--use_cuda', type=bool, default=True)\n",
    "parser.add_argument('--k', type=int, default=10, help='top k')\n",
    "parser.add_argument('--k1', type=float, default=1.5, help='BM25 parameter')\n",
    "parser.add_argument('--b', type=float, default=0.75, help='BM25 parameter')\n",
    "\n",
    "parser.add_argument\n",
    "\n",
    "config = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "# https://github.com/castorini/pyserini/blob/master/docs/experiments-msmarco-passage.md\n",
    "dataset_path = os.path.join(config.data_path, config.dataset)\n",
    "msmarco_url = 'https://msmarco.blob.core.windows.net/msmarcoranking/collectionandqueries.tar.gz'\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.mkdir(dataset_path)\n",
    "\n",
    "response = requests.get(msmarco_url, stream=True)\n",
    "file = tarfile.open(fileobj=response.raw, mode='r|gz')\n",
    "file.extractall(path=dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsv to jsonl\n",
    "tsv_path = os.path.join(dataset_path, 'collection.tsv')\n",
    "jsonl_path = os.path.join(dataset_path, 'collection.jsonl')\n",
    "os.system('python tools/scripts/msmarco/convert_collection_to_jsonl.py' +\n",
    "          f'--collection-path {tsv_path}' +\n",
    "          f'--output-folder {jsonl_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25Retriever:\n",
    "    def __init__(self) -> None:\n",
    "        pass \n",
    "    \n",
    "    def search(index_path:str=None):\n",
    "        searcher = SimpleSearcher(index_dir='')\n",
    "        searcher.set_bm25(k1=config.k1, b=config.b)\n",
    "    \n",
    "    def search_indexes(searcher, query, id, answers):\n",
    "        hits = searcher.search(query, k=config.k)\n",
    "        passages = []\n",
    "        \n",
    "        for i in range(len(hits)):\n",
    "            qas = dict()\n",
    "            qas['qas'] = [{'id': id, 'query': query, 'answers': answers}]\n",
    "            qas['context'] = json.loads(hits[i].raw)['contents']\n",
    "            qas[\"bm25_scores\"] = hits[i].score\n",
    "            passages.append(qas)\n",
    "            \n",
    "        return passages\n",
    "    \n",
    "# https://github.com/velocityCavalry/bm25-pyserini/blob/main/search_index.py#L64 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List \n",
    "from pygaggle.rerank.base import Reranker, Query, Text\n",
    "\n",
    "class LLaMAReranker(Reranker):\n",
    "    def __init__(self,\n",
    "                 model=None,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "    \n",
    "    def rerank(self, query: Query, texts: List[Text]) -> List[Text]:\n",
    "        query =\n",
    "        \n",
    "        return super().rerank(query, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model)\n",
    "model = AutoModelForCausalLM.from_pretrained(config.model,\n",
    "                                             quantization_config=quantization_config,\n",
    "                                             trust_remote_code=True,)\n",
    "\n",
    "model.config.use_cache=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type='CAUSAL_LM',\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules = [\"q_proj\", \"v_proj\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from translate import Translator\n",
    "translator=Translator(to_lang='en',from_lang='es')\n",
    "import sklearn.metrics.pairwise\n",
    "from tqdm import tnrange\n",
    "from sklearn.metrics import jaccard_score\n",
    "import scipy\n",
    "import re\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedder = SentenceTransformer('bert-base-nli-mean-tokens') #BERT BASE\n",
    "#embedder = SentenceTransformer('bert-large-nli-stsb-mean-tokens') # LARGE BERT\n",
    "\n",
    "corpus_embeddings=embedder.encode(raw_data['text'].to_list())\n",
    "\n",
    "queries=[\"VACHON CARROT CAKE\",\n",
    "         \"DEMPSTERS S WW HAMBURGER BUNS 8S\",\n",
    "         \"POM CINNAMON RAISIN BAGELS\"]\n",
    "query_embeddings = embedder.encode(queries)\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "closest_n = 5\n",
    "for query, query_embedding in zip(queries, query_embeddings):\n",
    "    distances = scipy.spatial.distance.cdist([query_embedding], corpus_embeddings, \"cosine\")[0]\n",
    "\n",
    "    results = zip(range(len(distances)), distances)\n",
    "    results = sorted(results, key=lambda x: x[1])\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for idx, distance in results[0:closest_n]:\n",
    "        print(raw_data['text'][idx].strip(), \"(Score: %.4f)\" % (1-distance))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
