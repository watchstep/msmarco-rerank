{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cathy\\.conda\\envs\\rerank\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\cathy\\.conda\\envs\\rerank\\lib\\site-packages\\bitsandbytes\\cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import requests\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "import transformers\n",
    "from peft import LoraConfig\n",
    "from transformers import (AutoTokenizer, \n",
    "                          AutoModel,\n",
    "                          AutoModelForCausalLM, \n",
    "                          BitsAndBytesConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('facebook/contriever-msmarco')\n",
    "model = AutoModel.from_pretrained('facebook/contriever-msmarco')\n",
    "\n",
    "sentences = [\n",
    "    \"Where was Marie Curie born?\",\n",
    "    \"Maria Sklodowska, later known as Marie Curie, was born on November 7, 1867.\",\n",
    "    \"Born in Paris on 15 May 1859, Pierre Curie was the son of Eug√®ne Curie, a doctor of French Catholic origin from Alsace.\"\n",
    "]\n",
    "\n",
    "# Apply tokenizer\n",
    "inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1066,  0.0164,  0.0547,  ..., -0.0065, -0.0631, -0.0280],\n",
       "         [ 0.0192, -0.0602,  0.0502,  ...,  0.1185, -0.0204, -0.0111],\n",
       "         [ 0.1103, -0.0207,  0.0044,  ...,  0.0599, -0.0432,  0.0183],\n",
       "         ...,\n",
       "         [ 0.0305, -0.2994, -0.0895,  ...,  0.2829,  0.0329,  0.0951],\n",
       "         [ 0.0298, -0.3350, -0.0862,  ...,  0.2983,  0.0351,  0.0803],\n",
       "         [ 0.0299, -0.2928, -0.0951,  ...,  0.2991,  0.0265,  0.0623]],\n",
       "\n",
       "        [[ 0.0799,  0.0201,  0.0418,  ...,  0.0752,  0.0130,  0.0336],\n",
       "         [-0.0250,  0.0173,  0.0594,  ...,  0.1173, -0.1175,  0.0543],\n",
       "         [ 0.0280,  0.0259, -0.0916,  ..., -0.1142, -0.0608,  0.1254],\n",
       "         ...,\n",
       "         [ 0.0315, -0.1623, -0.0734,  ...,  0.1735, -0.0453,  0.0775],\n",
       "         [ 0.0674, -0.1745, -0.0764,  ...,  0.1819, -0.0478,  0.0687],\n",
       "         [ 0.0397, -0.1430, -0.0823,  ...,  0.1684, -0.0414,  0.0401]],\n",
       "\n",
       "        [[ 0.0364, -0.0647,  0.0651,  ...,  0.0903,  0.0586,  0.0269],\n",
       "         [-0.0173,  0.2125,  0.0231,  ..., -0.0572,  0.0988, -0.2662],\n",
       "         [-0.0478, -0.1174, -0.1090,  ...,  0.0656,  0.0384, -0.0421],\n",
       "         ...,\n",
       "         [ 0.0904,  0.0055, -0.0863,  ...,  0.0272, -0.0274,  0.0982],\n",
       "         [-0.1369, -0.0950,  0.0118,  ..., -0.0915, -0.0675, -0.0088],\n",
       "         [-0.0762, -0.0748, -0.0086,  ...,  0.0026, -0.0144, -0.0229]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Contriever:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('facebook/contriever-msmarco')\n",
    "        self.model = AutoModel.from_pretrained('facebook/contriever-msmarco')\n",
    "        \n",
    "    def mean_pooling(self, token_embeddings, mask):\n",
    "        token_embeddings = token_embeddings.masked_fill(~mask[..., None].bool(), 0.)\n",
    "        sentence_embeddings = token_embeddings.sum(dim=1) / mask.sum(dim=1)[..., None]\n",
    "        return sentence_embeddings\n",
    "        \n",
    "    def retrieve(self, features, idx):\n",
    "        encoded_queries = features['encoded_']\n",
    "        encoded_corpus = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_scores(self, features, index):\n",
    "#         encoded_queries = features['encoded_queries']\n",
    "#         encoded_docs = features['encoded_docs'][index]\n",
    "#         emb_queries = self.model(**encoded_queries.to('cuda'))\n",
    "#         emb_docs = self.model(**encoded_docs.to('cuda'))\n",
    "#         emb_queries_av = mean_pooling(emb_queries[0], encoded_queries['attention_mask'])\n",
    "#         emb_docs_av = mean_pooling(emb_docs[0], encoded_docs['attention_mask'])\n",
    "#         scores = torch.bmm(emb_queries_av.unsqueeze(1), emb_docs_av.unsqueeze(-1)).squeeze()\n",
    "#         return_dict = {}\n",
    "#         return_dict['scores'] = scores\n",
    "#         return return_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rerank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
