{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import requests\n",
    "import tarfile\n",
    "import argparse\n",
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "import pyserini\n",
    "from pyserini.search import SimpleSearcher\n",
    "from pyserini.dsearch import SimpleDenseSearcher\n",
    "from pyserini.search.lucene import LuceneSearcher\n",
    "\n",
    "import transformers\n",
    "\n",
    "from peft import LoraConfig\n",
    "from transformers import (AutoTokenizer, \n",
    "                          AutoModelForCausalLM, \n",
    "                          BitsAndBytesConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Rerank')\n",
    "\n",
    "parser.add_argument('--model_name', type=str, default='facebook/opt-125m')\n",
    "parser.add_argument('--collection', type=str, default='msmarco-passage')\n",
    "parser.add_argument('--collections_path', type=str, default='./collections/')\n",
    "parser.add_argument('--seed',type=int, default=42)\n",
    "parser.add_argument('--batch_size', type=int, default=256)\n",
    "parser.add_argument('--max_len', type=int, default=40)\n",
    "parser.add_argument('--lr', type=float, default=1e-5)\n",
    "parser.add_argument('--max_epochs', type=int, default=10)\n",
    "parser.add_argument('--use_cuda', type=bool, default=False)\n",
    "parser.add_argument('--k', type=int, default=100, help='top k')\n",
    "parser.add_argument('--k1', type=float, default=1.5, help='BM25 parameter')\n",
    "parser.add_argument('--b', type=float, default=0.75, help='BM25 parameter')\n",
    "\n",
    "parser.add_argument\n",
    "\n",
    "config = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_msmarco_passage_jsonl(collections_path, ):\n",
    "    msmarco_passage_path = os.path.join(collections_path, 'msmarco-passage')\n",
    "    msmarco_url = 'https://msmarco.blob.core.windows.net/msmarcoranking/collectionandqueries.tar.gz'\n",
    "    \n",
    "    if not os.path.exists(msmarco_passage_path):\n",
    "        os.mkdir(msmarco_passage_path)\n",
    "        \n",
    "    response = requests.get(msmarco_url, stream=True)\n",
    "    file = tarfile.open(fileobj=response.raw, mode='r|gz')\n",
    "    file.extractall(path=msmarco_passage_path)\n",
    "    \n",
    "    tsv_path = os.path.join(msmarco_passage_path, 'collection.tsv')\n",
    "    jsonl_path = os.path.join(msmarco_passage_path, 'collection_jsonl')\n",
    "    \n",
    "    if os.path.exists(tsv_path):\n",
    "        os.system(f'python anserini-tools/scripts/msmarco/convert_collection_to_jsonl.py ' +\n",
    "                  f'--collection-path {tsv_path} ' +\n",
    "                  f'--output-folder {jsonl_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class Indexer:\n",
    "    def __init__(self, jsonl_path, index_path):\n",
    "        self.jsonl_path = jsonl_path\n",
    "        self.index_path = index_path\n",
    "    \n",
    "    def build_sparse_index(self):\n",
    "        execute_code = os.system('python -m pyserini.index.lucene ' + \n",
    "                                 '--collection JsonCollection ' +\n",
    "                                 f'--input {self.jsonl_path} ' +\n",
    "                                 f'--index {self.index_path} ' +\n",
    "                                 '--generator DefaultLuceneDocumentGenerator ' +\n",
    "                                 '--threads 1 --storeRaw')\n",
    "        if execute_code != 0:\n",
    "            raise Exception('Indexing Failed!')\n",
    "        else:\n",
    "            print('Indexing Success!')\n",
    "    \n",
    "    def build_dense_index(self):\n",
    "        pass \n",
    "\n",
    "class BM25Retriever:\n",
    "    def __init__(self, index_path, k, k1=1.5, b=0.75):\n",
    "        self.searcher = LuceneSearcher(index_path)\n",
    "        self.searcher.set_bm25(k1=k1, b=b)\n",
    "        self.k = k\n",
    "            \n",
    "    def _get_results(self, qid, hits:List):\n",
    "        results = []\n",
    "        \n",
    "        for i, hit in enumerate(hits):\n",
    "            docid = hit.docid\n",
    "            content = json.loads(hits[i].raw)['contents']\n",
    "            bm25_score = hit.score\n",
    "            result = {'rank': i+1,\n",
    "                      'qid': qid,\n",
    "                      'docid': docid, \n",
    "                      'score': bm25_score,\n",
    "                      'content': content}\n",
    "            results.append(result)\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    def _save_json(self, results:List[dict]):\n",
    "        json_path = os.path.join('./retrieved/', f'bm25-{config.collection}.json')\n",
    "        json_file = open(json_path, 'w', encoding='utf-8', newline='\\n')\n",
    "        for result in results:\n",
    "            json_file.write(json.dumps(result) + '\\n')\n",
    "        \n",
    "        json_file.close()\n",
    "    \n",
    "    def search(self, qid, query_text:str):\n",
    "        search_results = {}\n",
    "        hits = self.searcher.search(query_text, k=self.k,)\n",
    "        search_results['query'] = query_text\n",
    "        search_results['hits']  = self._get_results(qid, hits)\n",
    "        \n",
    "        return search_results\n",
    "    \n",
    "    def batch_search(self, qids, query_texts: List[str], is_save:bool):\n",
    "        query_dict = dict(zip(qids, query_texts))\n",
    "        batch_hits = self.searcher.batch_search(query_texts, qids, k=self.k, threads=multiprocessing.cpu_count())\n",
    "        bsearch_results = []\n",
    "        bsearch_items = {}\n",
    "\n",
    "        for qid, hits in batch_hits.items():\n",
    "            bsearch_items['query'] = query_dict[qid]\n",
    "            bsearch_items['hits'] = self._get_results(qid, hits)\n",
    "            bsearch_results.append(bsearch_items)\n",
    "            bsearch_items = {}\n",
    "            \n",
    "        if is_save:\n",
    "            self._save_json(bsearch_results)\n",
    "       \n",
    "        return bsearch_results\n",
    "    \n",
    "# if not os.path.exists(index_path):\n",
    "#             indexer = Indexer()\n",
    "#             self.build_sparse_index(jsonl_path, index_path)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_path:str):\n",
    "    with open(json_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        result = [json.loads(line) for line in lines]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_dir_path = os.path.join(config.collections_path, config.collection)\n",
    "collection_path = os.path.join(collection_dir_path, 'collection.tsv')\n",
    "queries_train_path = os.path.join(collection_dir_path, 'queries.train.tsv')\n",
    "queries_dev_path = os.path.join(collection_dir_path, 'queries.dev.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin:   1%|          | 21.0M/2.63G [00:15<09:53, 4.40MB/s]"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\cathy\\OneDrive\\바탕 화면\\rerank\\rerank_gpt.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/cathy/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/rerank/rerank_gpt.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m queries_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(queries_train_path, sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m'\u001b[39;49m, header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, names\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mqid\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cathy/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/rerank/rerank_gpt.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m queries_train\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\cathy\\.conda\\envs\\rerank\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\cathy\\.conda\\envs\\rerank\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    582\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 583\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\cathy\\.conda\\envs\\rerank\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1697\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   1698\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1699\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m     (\n\u001b[0;32m   1701\u001b[0m         index,\n\u001b[0;32m   1702\u001b[0m         columns,\n\u001b[0;32m   1703\u001b[0m         col_dict,\n\u001b[1;32m-> 1704\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1705\u001b[0m         nrows\n\u001b[0;32m   1706\u001b[0m     )\n\u001b[0;32m   1707\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1708\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\cathy\\.conda\\envs\\rerank\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mc:\\Users\\cathy\\.conda\\envs\\rerank\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:814\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\cathy\\.conda\\envs\\rerank\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:875\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\cathy\\.conda\\envs\\rerank\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:850\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\cathy\\.conda\\envs\\rerank\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:861\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\cathy\\.conda\\envs\\rerank\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:2029\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "queries_train = pd.read_csv(queries_train_path, sep='\\t', header=None, names=['qid', 'query'])\n",
    "queries_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 100\n",
    "# 후에 query 후보를 여러 개 생성해서..? 더 많이.?\n",
    "# llama2 chat 활용해서\n",
    "# https://huggingface.co/TheBloke/Llama-2-13B-chat-GPTQ/discussions/5\n",
    "llama2_prompt = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an intelligent assistant capable of generatig queries for given passages.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Please generate a query for the following {num} passages based on its content. \\nThe task is to generate a query that summarizes the main points of each passage. \\nThe query should be relevant to the content of the passage.\"\n",
    "    },\n",
    "    {\"role\": \"assistant\", \"content\": \"Okay, please provide the passages to generate a query.\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTReranker:\n",
    "    def __init__(self):\n",
    "        self.model = self.load_model(config.model_name, config.use_cuda)\n",
    "        self.tokenizer = self.load_tokenizer(config.model_name)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def load_model(self, model_name:str, use_cuda:bool):\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() & use_cuda else 'cpu')\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float32).to(device)\n",
    "        model.config.use_cache=True\n",
    "        return model\n",
    "    \n",
    "    def load_tokenizer(self, model_name:str):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        return tokenizer\n",
    "    \n",
    "    def _get_prompt(self, query)\n",
    "    \n",
    "    def rerank(self, query, texts):\n",
    "        prompt =  f\"Please generate a query based on the following passage: {texts}\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.01k/1.01k [00:00<00:00, 64.7kB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 526M/526M [03:20<00:00, 2.62MB/s] \n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 560/560 [00:00<00:00, 78.7kB/s]\n",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 899k/899k [00:01<00:00, 623kB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 744kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 357/357 [00:00<00:00, 84.7kB/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('EleutherAI/gpt-neo-125m')\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Please generate a question for the following passages: Since 2007, the RBA's outstanding reputation has been affected by the 'Securency' or NPA scandal. These RBA subsidiaries were involved in bribing overseas officials so that Australia might win lucrative note-printing contracts. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages = \"Since 2007, the RBA's outstanding reputation has been affected by the 'Securency' or NPA scandal. These RBA subsidiaries were involved in bribing overseas officials so that Australia might win lucrative note-printing contracts. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\"\n",
    "prompt =f\"Please generate a question for the following passages: {passages}\"\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "generate_ids = model.generate(inputs.input_ids, num_return_sequences=1, do_sample=True, num_beams=1, max_new_tokens=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Please generate a question for the following passages: Since 2007, the RBA's outstanding reputation has been affected by the 'Securency' or NPA scandal. These RBA subsidiaries were involved in bribing overseas officials so that Australia might win lucrative note-printing contracts. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\\n\\nWhen the first Australian Prime Minister, Andrew stress the importance of keeping the Australian dollar in the currency, he would be seen as representing an important development in\""
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generate_ids[0], skip_special_tokens=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please generate a query for the following passages: The presence of communication amid scientific minds was equally important to the success of the Manhattan Project as scientific intellect was.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please generate a query for the following passages: RBA Recognized with the 2014 Microsoft US Regional Partner of the ... by PR Newswire. Contract Awarded for supply and support the. Securitisations System used for risk management and analysis.                                                                             '"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=128)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(self, query, texts):\n",
    "        reranked_texts = []\n",
    "\n",
    "        # Encode the query text\n",
    "        query_inputs = self.tokenizer(query, return_tensors='pt', truncation=True, max_length=self.max_len, padding=True)\n",
    "\n",
    "        for text in texts:\n",
    "            # Encode the text\n",
    "            text_inputs = self.tokenizer(text, return_tensors='pt', truncation=True, max_length=self.max_len, padding=True)\n",
    "\n",
    "            # Generate the reranking input by concatenating query and text\n",
    "            rerank_input = {\n",
    "                'input_ids': torch.cat([query_inputs['input_ids'], text_inputs['input_ids']], dim=1),\n",
    "                'attention_mask': torch.cat([query_inputs['attention_mask'], text_inputs['attention_mask']], dim=1)\n",
    "            }\n",
    "\n",
    "            # Generate reranking scores using the GPT model\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(**rerank_input).logits\n",
    "\n",
    "            # Calculate the total score by summing logits\n",
    "            total_score = logits.sum().item()\n",
    "\n",
    "            # Append text and total score to the reranked_texts\n",
    "            reranked_texts.append({'text': text, 'total_score': total_score})\n",
    "\n",
    "        # Sort texts based on total_score in descending order\n",
    "        reranked_texts.sort(key=lambda x: x['total_score'], reverse=True)\n",
    "\n",
    "        # Extract the sorted texts\n",
    "        sorted_texts = [item['text'] for item in reranked_texts]\n",
    "\n",
    "        return sorted_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rerank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
