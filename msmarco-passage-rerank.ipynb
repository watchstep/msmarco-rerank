{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cathy\\.conda\\envs\\rerank\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\cathy\\.conda\\envs\\rerank\\lib\\site-packages\\bitsandbytes\\cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import requests\n",
    "import tarfile\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "import transformers\n",
    "from peft import LoraConfig\n",
    "from transformers import (AutoTokenizer, \n",
    "                          AutoModelForCausalLM, \n",
    "                          BitsAndBytesConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Rerank')\n",
    "\n",
    "parser.add_argument('--model_name', type=str, default='facebook/opt-125m')\n",
    "parser.add_argument('--collection', type=str, default='msmarco-passage')\n",
    "parser.add_argument('--collections_path', type=str, default='./collections/')\n",
    "parser.add_argument('--seed',type=int, default=42)\n",
    "parser.add_argument('--batch_size', type=int, default=256)\n",
    "parser.add_argument('--max_len', type=int, default=40)\n",
    "parser.add_argument('--lr', type=float, default=1e-5)\n",
    "parser.add_argument('--max_epochs', type=int, default=10)\n",
    "parser.add_argument('--use_cuda', type=bool, default=False)\n",
    "parser.add_argument('--k', type=int, default=100, help='top k')\n",
    "parser.add_argument('--k1', type=float, default=1.5, help='BM25 parameter')\n",
    "parser.add_argument('--b', type=float, default=0.75, help='BM25 parameter')\n",
    "\n",
    "parser.add_argument\n",
    "\n",
    "config = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_msmarco_passage_jsonl(collections_path, ):\n",
    "    msmarco_passage_path = os.path.join(collections_path, 'msmarco-passage')\n",
    "    # https://microsoft.github.io/msmarco/Datasets\n",
    "    msmarco_url = 'https://msmarco.blob.core.windows.net/msmarcoranking/collectionandqueries.tar.gz'\n",
    "    \n",
    "    if not os.path.exists(msmarco_passage_path):\n",
    "        os.mkdir(msmarco_passage_path)\n",
    "        \n",
    "    response = requests.get(msmarco_url, stream=True)\n",
    "    file = tarfile.open(fileobj=response.raw, mode='r|gz')\n",
    "    file.extractall(path=msmarco_passage_path)\n",
    "    \n",
    "    tsv_path = os.path.join(msmarco_passage_path, 'collection.tsv')\n",
    "    jsonl_path = os.path.join(msmarco_passage_path, 'collection_jsonl')\n",
    "    \n",
    "    if os.path.exists(tsv_path):\n",
    "        os.system(f'python anserini-tools/scripts/msmarco/convert_collection_to_jsonl.py ' +\n",
    "                  f'--collection-path {tsv_path} ' +\n",
    "                  f'--output-folder {jsonl_path}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_msmarco_passage_top1000_tr():\n",
    "    top1000_tr_url = 'https://msmarco.blob.core.windows.net/msmarcoranking/top1000.train.tar.gz'\n",
    "    response = requests.get(top1000_tr_url, stream=True)\n",
    "    file = tarfile.open(fileobj=response.raw, mode='r|gz')\n",
    "    file.extractall(path='./collections/msmarco-passage')\n",
    "\n",
    "def get_msmarco_passage_top1000_dev():\n",
    "    top1000_dev_url = 'https://msmarco.blob.core.windows.net/msmarcoranking/top1000.dev.tar.gz'\n",
    "    response = requests.get(top1000_dev_url, stream=True)\n",
    "    file = tarfile.open(fileobj=response.raw, mode='r|gz')\n",
    "    file.extractall(path='./collections/msmarco-passage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\cathy\\OneDrive - 연세대학교 (Yonsei University)\\rerank\\msmarco-passage-rerank.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cathy/OneDrive%20-%20%EC%97%B0%EC%84%B8%EB%8C%80%ED%95%99%EA%B5%90%20%28Yonsei%20University%29/rerank/msmarco-passage-rerank.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtarfile\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cathy/OneDrive%20-%20%EC%97%B0%EC%84%B8%EB%8C%80%ED%95%99%EA%B5%90%20%28Yonsei%20University%29/rerank/msmarco-passage-rerank.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m file \u001b[39m=\u001b[39m tarfile\u001b[39m.\u001b[39mopen(\u001b[39m'\u001b[39m\u001b[39m./collections/msmarco-passage/top1000.train.tar.gz\u001b[39m\u001b[39m'\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mr|gz\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/cathy/OneDrive%20-%20%EC%97%B0%EC%84%B8%EB%8C%80%ED%95%99%EA%B5%90%20%28Yonsei%20University%29/rerank/msmarco-passage-rerank.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m file\u001b[39m.\u001b[39;49mextractall(path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./collections/msmarco-passage\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\cathy\\.conda\\envs\\rerank\\lib\\tarfile.py:2241\u001b[0m, in \u001b[0;36mTarFile.extractall\u001b[1;34m(self, path, members, numeric_owner, filter)\u001b[0m\n\u001b[0;32m   2236\u001b[0m     \u001b[39mif\u001b[39;00m tarinfo\u001b[39m.\u001b[39misdir():\n\u001b[0;32m   2237\u001b[0m         \u001b[39m# For directories, delay setting attributes until later,\u001b[39;00m\n\u001b[0;32m   2238\u001b[0m         \u001b[39m# since permissions can interfere with extraction and\u001b[39;00m\n\u001b[0;32m   2239\u001b[0m         \u001b[39m# extracting contents can reset mtime.\u001b[39;00m\n\u001b[0;32m   2240\u001b[0m         directories\u001b[39m.\u001b[39mappend(tarinfo)\n\u001b[1;32m-> 2241\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extract_one(tarinfo, path, set_attrs\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m tarinfo\u001b[39m.\u001b[39;49misdir(),\n\u001b[0;32m   2242\u001b[0m                       numeric_owner\u001b[39m=\u001b[39;49mnumeric_owner)\n\u001b[0;32m   2244\u001b[0m \u001b[39m# Reverse sort directories.\u001b[39;00m\n\u001b[0;32m   2245\u001b[0m directories\u001b[39m.\u001b[39msort(key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m a: a\u001b[39m.\u001b[39mname, reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\cathy\\.conda\\envs\\rerank\\lib\\tarfile.py:2308\u001b[0m, in \u001b[0;36mTarFile._extract_one\u001b[1;34m(self, tarinfo, path, set_attrs, numeric_owner)\u001b[0m\n\u001b[0;32m   2304\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extract_member(tarinfo, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, tarinfo\u001b[39m.\u001b[39mname),\n\u001b[0;32m   2305\u001b[0m                          set_attrs\u001b[39m=\u001b[39mset_attrs,\n\u001b[0;32m   2306\u001b[0m                          numeric_owner\u001b[39m=\u001b[39mnumeric_owner)\n\u001b[0;32m   2307\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 2308\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_fatal_error(e)\n\u001b[0;32m   2309\u001b[0m \u001b[39mexcept\u001b[39;00m ExtractError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   2310\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_nonfatal_error(e)\n",
      "File \u001b[1;32mc:\\Users\\cathy\\.conda\\envs\\rerank\\lib\\tarfile.py:2304\u001b[0m, in \u001b[0;36mTarFile._extract_one\u001b[1;34m(self, tarinfo, path, set_attrs, numeric_owner)\u001b[0m\n\u001b[0;32m   2301\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check(\u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2303\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2304\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extract_member(tarinfo, os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(path, tarinfo\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m   2305\u001b[0m                          set_attrs\u001b[39m=\u001b[39;49mset_attrs,\n\u001b[0;32m   2306\u001b[0m                          numeric_owner\u001b[39m=\u001b[39;49mnumeric_owner)\n\u001b[0;32m   2307\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   2308\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_fatal_error(e)\n",
      "File \u001b[1;32mc:\\Users\\cathy\\.conda\\envs\\rerank\\lib\\tarfile.py:2386\u001b[0m, in \u001b[0;36mTarFile._extract_member\u001b[1;34m(self, tarinfo, targetpath, set_attrs, numeric_owner)\u001b[0m\n\u001b[0;32m   2383\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dbg(\u001b[39m1\u001b[39m, tarinfo\u001b[39m.\u001b[39mname)\n\u001b[0;32m   2385\u001b[0m \u001b[39mif\u001b[39;00m tarinfo\u001b[39m.\u001b[39misreg():\n\u001b[1;32m-> 2386\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmakefile(tarinfo, targetpath)\n\u001b[0;32m   2387\u001b[0m \u001b[39melif\u001b[39;00m tarinfo\u001b[39m.\u001b[39misdir():\n\u001b[0;32m   2388\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmakedir(tarinfo, targetpath)\n",
      "File \u001b[1;32mc:\\Users\\cathy\\.conda\\envs\\rerank\\lib\\tarfile.py:2439\u001b[0m, in \u001b[0;36mTarFile.makefile\u001b[1;34m(self, tarinfo, targetpath)\u001b[0m\n\u001b[0;32m   2437\u001b[0m     target\u001b[39m.\u001b[39mtruncate()\n\u001b[0;32m   2438\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2439\u001b[0m     copyfileobj(source, target, tarinfo\u001b[39m.\u001b[39;49msize, ReadError, bufsize)\n",
      "File \u001b[1;32mc:\\Users\\cathy\\.conda\\envs\\rerank\\lib\\tarfile.py:254\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[1;34m(src, dst, length, exception, bufsize)\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buf) \u001b[39m<\u001b[39m bufsize:\n\u001b[0;32m    253\u001b[0m         \u001b[39mraise\u001b[39;00m exception(\u001b[39m\"\u001b[39m\u001b[39munexpected end of data\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 254\u001b[0m     dst\u001b[39m.\u001b[39;49mwrite(buf)\n\u001b[0;32m    256\u001b[0m \u001b[39mif\u001b[39;00m remainder \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    257\u001b[0m     buf \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mread(remainder)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "file = tarfile.open('./collections/msmarco-passage/top1000.train.tar.gz', mode='r|gz')\n",
    "file.extractall(path='./collections/msmarco-passage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_msmarco_passage_top1000_dev()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_dir_path = os.path.join(config.collections_path, config.collection)\n",
    "collection_path = os.path.join(collection_dir_path, 'collection.tsv')\n",
    "queries_tr_path = os.path.join(collection_dir_path, 'queries.train.tsv')\n",
    "qrels_tr_path = os.path.join(collection_dir_path, 'qrels.train.tsv')\n",
    "qrels_dev_path = os.path.join(collection_dir_path, 'qrels.dev.tsv')\n",
    "queries_dev_path = os.path.join(collection_dir_path, 'queries.dev.tsv')\n",
    "queries_eval_path = os.path.join(collection_dir_path, 'queries.eval.tsv')\n",
    "top1000_tr_path = os.path.join(collection_dir_path, 'top1000.train')\n",
    "top1000_dev_path = os.path.join(collection_dir_path, 'top1000.dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1048578</th>\n",
       "      <td>cost of endless pools/swim spa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048579</th>\n",
       "      <td>what is pcnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048580</th>\n",
       "      <td>what is pcb waste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048581</th>\n",
       "      <td>what is pbis?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048582</th>\n",
       "      <td>what is paysky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480594</th>\n",
       "      <td>price of copper by ounce, pound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524271</th>\n",
       "      <td>trazodone for dogs side effects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048565</th>\n",
       "      <td>who plays sebastian michaelis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>what is pearls before swine?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524285</th>\n",
       "      <td>treadmill incline meaning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101093 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   query\n",
       "qid                                     \n",
       "1048578   cost of endless pools/swim spa\n",
       "1048579                     what is pcnt\n",
       "1048580                what is pcb waste\n",
       "1048581                    what is pbis?\n",
       "1048582                   what is paysky\n",
       "...                                  ...\n",
       "480594   price of copper by ounce, pound\n",
       "524271   trazodone for dogs side effects\n",
       "1048565    who plays sebastian michaelis\n",
       "1048570     what is pearls before swine?\n",
       "524285         treadmill incline meaning\n",
       "\n",
       "[101093 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = pd.read_csv(queries_dev_path, sep='\\t', header=None, names=['qid', 'query'], index_col='qid')\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "query            foods and supplements to lower blood sugar\n",
       "corpus    Watch portion sizes: ■ Even healthy foods will...\n",
       "Name: (188714, 1000052), dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qr.loc[qr.index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qid</th>\n",
       "      <th>pid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188714</th>\n",
       "      <th>1000052</th>\n",
       "      <td>foods and supplements to lower blood sugar</td>\n",
       "      <td>Watch portion sizes: ■ Even healthy foods will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082792</th>\n",
       "      <th>1000084</th>\n",
       "      <td>what does the golgi apparatus do to the protei...</td>\n",
       "      <td>Start studying Bonding, Carbs, Proteins, Lipid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995526</th>\n",
       "      <th>1000094</th>\n",
       "      <td>where is the federal penitentiary in ind</td>\n",
       "      <td>It takes THOUSANDS of Macy's associates to bri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199776</th>\n",
       "      <th>1000115</th>\n",
       "      <td>health benefits of eating vegetarian</td>\n",
       "      <td>The good news is that you will discover what g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660957</th>\n",
       "      <th>1000115</th>\n",
       "      <td>what foods are good if you have gout?</td>\n",
       "      <td>The good news is that you will discover what g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679360</th>\n",
       "      <th>999933</th>\n",
       "      <td>what is a corporate bylaws</td>\n",
       "      <td>Corporate Records for Nonprofit Corporations. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36388</th>\n",
       "      <th>999956</th>\n",
       "      <td>average family savings account</td>\n",
       "      <td>When it comes to average retirement savings st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43781</th>\n",
       "      <th>999956</th>\n",
       "      <td>average savings per age group</td>\n",
       "      <td>When it comes to average retirement savings st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28442</th>\n",
       "      <th>999956</th>\n",
       "      <td>at what age does the average person retire</td>\n",
       "      <td>When it comes to average retirement savings st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36473</th>\n",
       "      <th>999956</th>\n",
       "      <td>average fifty year old retirement savings</td>\n",
       "      <td>When it comes to average retirement savings st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6668967 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             query  \\\n",
       "qid     pid                                                          \n",
       "188714  1000052         foods and supplements to lower blood sugar   \n",
       "1082792 1000084  what does the golgi apparatus do to the protei...   \n",
       "995526  1000094           where is the federal penitentiary in ind   \n",
       "199776  1000115               health benefits of eating vegetarian   \n",
       "660957  1000115              what foods are good if you have gout?   \n",
       "...                                                            ...   \n",
       "679360  999933                          what is a corporate bylaws   \n",
       "36388   999956                      average family savings account   \n",
       "43781   999956                       average savings per age group   \n",
       "28442   999956          at what age does the average person retire   \n",
       "36473   999956           average fifty year old retirement savings   \n",
       "\n",
       "                                                            corpus  \n",
       "qid     pid                                                         \n",
       "188714  1000052  Watch portion sizes: ■ Even healthy foods will...  \n",
       "1082792 1000084  Start studying Bonding, Carbs, Proteins, Lipid...  \n",
       "995526  1000094  It takes THOUSANDS of Macy's associates to bri...  \n",
       "199776  1000115  The good news is that you will discover what g...  \n",
       "660957  1000115  The good news is that you will discover what g...  \n",
       "...                                                            ...  \n",
       "679360  999933   Corporate Records for Nonprofit Corporations. ...  \n",
       "36388   999956   When it comes to average retirement savings st...  \n",
       "43781   999956   When it comes to average retirement savings st...  \n",
       "28442   999956   When it comes to average retirement savings st...  \n",
       "36473   999956   When it comes to average retirement savings st...  \n",
       "\n",
       "[6668967 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qr = pd.read_csv(top1000_dev_path, sep='\\t', header=None, names=['qid', 'pid', 'query', 'corpus']).set_index([\"qid\", \"pid\"])\n",
    "qr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/models?search=gpt+neo\n",
    "GPT_PRETRAINED_MODEL_LIST = [\n",
    "    'gpt-neo-125m',\n",
    "    'gpt-neo-2.7B',\n",
    "    'gpt-neo-1.3B'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarcoDataset:\n",
    "    def __init__(self, collection_dir_path, tokenizer, mode='train'):\n",
    "        self.collection_dir_path = collection_dir_path\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.queries)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        query = self.queries.iloc[idx].query\n",
    "        corpus = self.collection.iloc[idx].corpus \n",
    "        \n",
    "        encoding = self.get_encoding(query, corpus, idx)\n",
    "    \n",
    "    def get_encoding(self, query, corpus, idx):\n",
    "        qids = self.tokenizer(query, max_length=128, truncation=True).input_ids\n",
    "        cids = self.tokenizer(corpus, max_length=512, truncation=True).input_ids\n",
    "        ids = cids + qids\n",
    "        encoding = self.tokenizer.encode()\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, IterableDataset\n",
    "\n",
    "class MarcoEncodeDataset(Dataset):\n",
    "    def __init__(self, collection_dir, tokenizer, mode='train', q_max_len=64, p_max_len=256):\n",
    "        self.collection_dir = collection_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mode = mode\n",
    "        self.q_max_len = q_max_len\n",
    "        self.p_max_len = p_max_len\n",
    "        # load data\n",
    "        passages_path = os.path.join(collection_dir, 'collection.tsv')\n",
    "        queries_path = os.path.join(collection_dir, f'queries.{mode}.tsv')\n",
    "        qrels_path = os.path.join(collection_dir, f'qrels.{mode}.tsv')\n",
    "        top1000_path = os.path.join(collection_dir, 'top1000.{mode}')\n",
    "        self.passages = pd.read_csv(passages_path, sep='\\t', header=None, names=['pid', 'passage'], index_col='pid')\n",
    "        self.queries = pd.read_csv(queries_path, sep='\\t', header=None, names=['qid', 'query'], index_col='qid')\n",
    "        self.relations = pd.read_csv(qrels_path, sep='\\t', header=None, names=['qid', '0', 'pid', 'label'])\n",
    "        self.top1000 = pd.read_csv(top1000_path, sep='\\t', header=None, names=['qid', 'pid', 'query', 'passage'])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.top1000)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.top1000.iloc[idx]\n",
    "        query = self.queries.loc[x.qid].query\n",
    "        passage = self.collection.loc[x.pid].passage \n",
    "        label = 0 if self.relations.loc[(self.relations['qid'] == x.qid) & (self.relations['pid'] == x.pid)].empty else 1\n",
    "        \n",
    "        encoded = self.tokenizer.encode_plus(\n",
    "            passage,\n",
    "            max_length=self.p_max_len,\n",
    "            truncation='only_first',\n",
    "            return_attention_mask=False,\n",
    "            return_token_type_ids=True,\n",
    "            pad_to_max_length=True,\n",
    "        )\n",
    "        \n",
    "        encoded['attention_mask'] = torch.tensor(encoded['attention_mask'])\n",
    "\n",
    "        encoded['input_ids'] = torch.tensor(encoded['input_ids'])\n",
    "\n",
    "        encoded.update({'label': torch.LongTensor([label]),\n",
    "                        'idx': torch.tensor(idx)})\n",
    "        \n",
    "        return encoded\n",
    "    \n",
    "#   feature_dict = {\n",
    "#             \"input_ids\": passage_outputs[\"input_ids\"],\n",
    "#             \"attention_mask\": passage_outputs[\"attention_mask\"],\n",
    "\n",
    "#             \"input_ids_query\": query_outputs[\"input_ids\"],\n",
    "#             \"attention_mask_query\": query_outputs[\"attention_mask\"],\n",
    "\n",
    "#             \"qids\": qid,\n",
    "#             \"pids\": pid,\n",
    "#             \"binary_labels\": label,\n",
    "#         }\n",
    "\n",
    "# def collate_fn(batch):\n",
    "#     max_length = 32 + 256 + 3\n",
    "#     input_ids_lst = [x['query_input_ids'] + x['passage_input_ids'] for x in batch]\n",
    "#     token_type_ids_lst = [[0]*len(x['query_input_ids']) + [1]*len(x['passage_input_ids']) for x in batch]\n",
    "#     position_ids_lst = [list(range(len(x[\"query_input_ids\"]) + len(x[\"doc_input_ids\"]))) for x in batch]\n",
    "#         data = {\n",
    "#             \"input_ids\": pack_tensor_2D(input_ids_lst, default=0, dtype=torch.int64, length=max_length),\n",
    "#             \"token_type_ids\": pack_tensor_2D(token_type_ids_lst, default=0, dtype=torch.int64, length=max_length),\n",
    "#             \"position_ids\": pack_tensor_2D(position_ids_lst, default=0, dtype=torch.int64, length=max_length),\n",
    "#         }\n",
    "#         qid_lst = [x['qid'] for x in batch]\n",
    "#         docid_lst = [x['docid'] for x in batch]\n",
    "#         if mode == \"train\":\n",
    "\n",
    "#             data[\"labels\"] = torch.tensor([x[\"label\"] for x in batch], dtype=torch.int64)  \n",
    "#         return data, qid_lst, docid_lst\n",
    "#     return collate_function\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, IterableDataset\n",
    "\n",
    "# https://github.com/OpenMatch/OpenMatch/blob/ad1d6228bcf288ebe86037f93cd4ae20061ec4ea/src/openmatch/retriever/reranker.py\n",
    "def RerankDataset(IterableDataset):\n",
    "    def __init__(self, tokenizer, query_dataset, corpus_dataset):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.query_dataset = query_dataset\n",
    "        self.corpus_dataset = corpus_dataset\n",
    "        \n",
    "    # def __iter__(self):\n",
    "    #     for qid, did in items():\n",
    "    #         yield \n",
    "    #         {\n",
    "    #                 \"query_id\": qid, \n",
    "    #                 \"doc_id\": did, \n",
    "    #                 **encode_pair(\n",
    "    #                     self.tokenizer, \n",
    "    #                     self.query_dataset[qid][\"input_ids\"], \n",
    "    #                     self.corpus_dataset[did][\"input_ids\"], \n",
    "    #                     self.query_dataset.max_len, \n",
    "    #                     self.corpus_dataset.max_len,\n",
    "    #                     encode_as_text_pair=self.encode_as_text_pair\n",
    "    #                 ),\n",
    "    #             }\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTReranker:\n",
    "    def __init__(self):\n",
    "        self.model = self.load_model(config.model_name, config.use_cuda)\n",
    "        self.tokenizer = self.load_tokenizer(config.model_name)\n",
    "        self.model.eval()\n",
    "    \n",
    "    def load_model(self, model_name:str, use_cuda:bool):\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() & use_cuda else 'cpu')\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float32).to(device)\n",
    "        model.config.use_cache=True\n",
    "        return model\n",
    "    \n",
    "    def load_tokenizer(self, model_name:str):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        return tokenizer\n",
    "    \n",
    "    def _get_prompt(self, query)\n",
    "    \n",
    "    def rerank(self, query, texts):\n",
    "        prompt =  f\"Please generate a query based on the following passage: {texts}\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('EleutherAI/gpt-neo-125m')\n",
    "tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-125m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(self, query, texts):\n",
    "        reranked_texts = []\n",
    "\n",
    "        # Encode the query text\n",
    "        query_inputs = self.tokenizer(query, return_tensors='pt', truncation=True, max_length=self.max_len, padding=True)\n",
    "\n",
    "        for text in texts:\n",
    "            # Encode the text\n",
    "            text_inputs = self.tokenizer(text, return_tensors='pt', truncation=True, max_length=self.max_len, padding=True)\n",
    "\n",
    "            # Generate the reranking input by concatenating query and text\n",
    "            rerank_input = {\n",
    "                'input_ids': torch.cat([query_inputs['input_ids'], text_inputs['input_ids']], dim=1),\n",
    "                'attention_mask': torch.cat([query_inputs['attention_mask'], text_inputs['attention_mask']], dim=1)\n",
    "            }\n",
    "\n",
    "            # Generate reranking scores using the GPT model\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(**rerank_input).logits\n",
    "\n",
    "            # Calculate the total score by summing logits\n",
    "            total_score = logits.sum().item()\n",
    "\n",
    "            # Append text and total score to the reranked_texts\n",
    "            reranked_texts.append({'text': text, 'total_score': total_score})\n",
    "\n",
    "        # Sort texts based on total_score in descending order\n",
    "        reranked_texts.sort(key=lambda x: x['total_score'], reverse=True)\n",
    "\n",
    "        # Extract the sorted texts\n",
    "        sorted_texts = [item['text'] for item in reranked_texts]\n",
    "\n",
    "        return sorted_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rerank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
